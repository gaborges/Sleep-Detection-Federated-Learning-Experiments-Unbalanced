{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2701ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:15:56.240739: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 14:15:56.546737: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-23 14:15:57.189698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-02-23 14:15:57.191867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-02-23 14:15:57.191881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# example of random oversampling to balance the class distribution\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TIME_SERIES_SIZE = 2   # Determines the window size. Ex (4,9)\n",
    "TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e61842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    return results\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f392d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized.csv\")\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "#X_train = pd.read_csv(baseFolder+\"train/allData-classification-numeric-normalized_balanced_undersample.csv\")\n",
    "#X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized_balanced_oversample.csv\")\n",
    "\n",
    "#AA = pd.read_csv(baseFolder+\"allData-classification-numeric-normalized.csv\")\n",
    "#X_train, X_test = train_test_split(AA,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413d6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 407452 entries, 0 to 407451\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            407452 non-null  float64\n",
      " 1   location            407452 non-null  float64\n",
      " 2   timestamp           407452 non-null  float64\n",
      " 3   day_of_week         407452 non-null  float64\n",
      " 4   light               407452 non-null  float64\n",
      " 5   phone_lock          407452 non-null  float64\n",
      " 6   proximity           407452 non-null  float64\n",
      " 7   sound               407452 non-null  float64\n",
      " 8   time_to_next_alarm  407452 non-null  float64\n",
      " 9   minutes_day         407452 non-null  float64\n",
      " 10  timestamp_text      407452 non-null  object \n",
      " 11  class               407452 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 37.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2018-05-15 14:20:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>2018-05-15 14:20:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.210603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604408</td>\n",
       "      <td>0.982044</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>2018-05-15 14:21:15</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.210603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604408</td>\n",
       "      <td>0.982044</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>2018-05-15 14:21:45</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.210603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601849</td>\n",
       "      <td>0.981944</td>\n",
       "      <td>0.599027</td>\n",
       "      <td>2018-05-15 14:22:15</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407447</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.549687</td>\n",
       "      <td>2018-06-12 13:11:39</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407448</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644370</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.550382</td>\n",
       "      <td>2018-06-12 13:12:09</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407449</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624127</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.551077</td>\n",
       "      <td>2018-06-12 13:13:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407450</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540295</td>\n",
       "      <td>0.992758</td>\n",
       "      <td>0.551772</td>\n",
       "      <td>2018-06-12 13:14:07</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407451</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581746</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.562196</td>\n",
       "      <td>2018-06-12 13:29:33</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407452 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       0.0   0.210603          0.0  0.000175         0.0   \n",
       "1           0.00       0.0   0.210603          0.0  0.000175         0.0   \n",
       "2           0.25       0.5   0.210603          0.0  0.000165         0.0   \n",
       "3           0.25       0.5   0.210603          0.0  0.001449         0.0   \n",
       "4           0.25       0.5   0.210603          0.0  0.000198         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "407447      0.25       1.0   0.215387          0.0  0.000000         1.0   \n",
       "407448      0.25       1.0   0.215387          0.0  0.000000         1.0   \n",
       "407449      0.25       1.0   0.215387          0.0  0.000538         1.0   \n",
       "407450      0.00       1.0   0.215387          0.0  0.000000         0.0   \n",
       "407451      0.25       0.0   0.215389          0.0  0.000005         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.000000            0.982143     0.597637   \n",
       "1             1.0  0.000000            0.982143     0.597637   \n",
       "2             1.0  0.604408            0.982044     0.598332   \n",
       "3             1.0  0.604408            0.982044     0.598332   \n",
       "4             1.0  0.601849            0.981944     0.599027   \n",
       "...           ...       ...                 ...          ...   \n",
       "407447        1.0  0.644370            0.992956     0.549687   \n",
       "407448        1.0  0.644370            0.992956     0.550382   \n",
       "407449        1.0  0.624127            0.992857     0.551077   \n",
       "407450        0.0  0.540295            0.992758     0.551772   \n",
       "407451        0.0  0.581746            0.991171     0.562196   \n",
       "\n",
       "             timestamp_text  class  \n",
       "0       2018-05-15 14:20:45  awake  \n",
       "1       2018-05-15 14:20:45  awake  \n",
       "2       2018-05-15 14:21:15  awake  \n",
       "3       2018-05-15 14:21:45  awake  \n",
       "4       2018-05-15 14:22:15  awake  \n",
       "...                     ...    ...  \n",
       "407447  2018-06-12 13:11:39  awake  \n",
       "407448  2018-06-12 13:12:09  awake  \n",
       "407449  2018-06-12 13:13:37  awake  \n",
       "407450  2018-06-12 13:14:07  awake  \n",
       "407451  2018-06-12 13:29:33  awake  \n",
       "\n",
       "[407452 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.info())\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5feb752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_train = transform_output_nominal_class_into_one_hot_encoding(X_train)\n",
    "\n",
    "\n",
    "# transforms the input data to float32\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "# transforms the input data to float32\n",
    "X_train = transform_data_type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf8855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (407450, 2, 9) (407450, 2)\n",
      "Size:  (136284, 2, 9) (136284, 2)\n"
     ]
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_train_data = pd.DataFrame(data=X_train,columns=inputFeatures)\n",
    "y_train_data = pd.DataFrame(data=X_train,columns=outputClasses)\n",
    "# selec test dataset (fixed to all)\n",
    "X_test_data = pd.DataFrame(data=X_test,columns=inputFeatures)\n",
    "y_test_data = pd.DataFrame(data=X_test,columns=outputClasses)\n",
    "\n",
    "X_train_data, y_train_data = create_dataset_time_series_with_one_output(   #timestamp\n",
    "    X_train_data, \n",
    "    y_train_data, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "X_test_data, y_test_data = create_dataset_time_series_with_one_output(    #timestamp\n",
    "    X_test_data, \n",
    "    y_test_data, \n",
    "    TIME_SERIES_SIZE, \n",
    "    TIME_STEP_SHIFT\n",
    ")\n",
    "\n",
    "\n",
    "print(\"shape: \",X_train_data.shape, y_train_data.shape)\n",
    "print(\"Size: \",X_test_data.shape,y_test_data.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7518d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:18:36.746360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:36.789689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:36.790029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:36.790931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 14:18:36.793454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:36.793804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:36.794068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:37.491658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:37.492031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:37.492046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-23 14:18:37.492382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-23 14:18:37.492479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# transtorm data to tensor slices\n",
    "test_dataset_series = tf.data.Dataset.from_tensor_slices((X_test_data, y_test_data))\n",
    "train_dataset_series = tf.data.Dataset.from_tensor_slices((X_train_data, y_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de06a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(2, 9), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc486e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client_test_dataset.window(size=4, shift=1, stride=1, drop_remainder=True)\n",
    "#test_dataset_series.batch(BATCH_SIZE) # usado no federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97211c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 2, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch data size\n",
    "test_dataset_series1 = test_dataset_series.batch(BATCH_SIZE)\n",
    "train_dataset_series1 = train_dataset_series.batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset_series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06366f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c846c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 14:18:45.975506: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-02-23 14:18:51.948780: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12733/12733 [==============================] - 110s 8ms/step - loss: 0.4606 - categorical_accuracy: 0.7997\n",
      "Epoch 2/2\n",
      "12733/12733 [==============================] - 97s 8ms/step - loss: 0.4513 - categorical_accuracy: 0.8054\n",
      "4259/4259 [==============================] - 11s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.811387\n",
      "Precision: 0.811085\n",
      "Recall: 0.999592\n",
      "F1 score: 0.895526\n",
      "Cohens kappa: 0.024572\n",
      "ROC AUC: 0.736209\n",
      "\\Confusion Matrix\n",
      "[[   411  25660]\n",
      " [    45 110168]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.813133\n",
      "Precision: 0.896930\n",
      "Recall: 0.015835\n",
      "F1 score: 0.031120\n",
      "Cohens kappa: 0.024707\n",
      "ROC AUC: 0.736682\n",
      "\\Confusion Matrix\n",
      "[[110408     47]\n",
      " [ 25420    409]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8122596929940418\n",
      "precision:  0.854007215782189\n",
      "recall:  0.5077133069762128\n",
      "f1_score:  0.46332297668580813\n",
      "cohen_kappa_score:  0.024639547125285877\n",
      "roc_auc_score:  0.7364456715052952\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d4a52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n",
      "12733/12733 [==============================] - 98s 8ms/step - loss: 0.4616 - categorical_accuracy: 0.7987\n",
      "Epoch 2/2\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.4513 - categorical_accuracy: 0.8052\n",
      "4259/4259 [==============================] - 12s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.811240\n",
      "Precision: 0.810956\n",
      "Recall: 0.999610\n",
      "F1 score: 0.895454\n",
      "Cohens kappa: 0.023264\n",
      "ROC AUC: 0.737859\n",
      "\\Confusion Matrix\n",
      "[[   389  25682]\n",
      " [    43 110170]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.812986\n",
      "Precision: 0.895833\n",
      "Recall: 0.014983\n",
      "F1 score: 0.029473\n",
      "Cohens kappa: 0.023384\n",
      "ROC AUC: 0.738361\n",
      "\\Confusion Matrix\n",
      "[[110410     45]\n",
      " [ 25442    387]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8121129406239911\n",
      "precision:  0.8533946868651179\n",
      "recall:  0.507296502426824\n",
      "f1_score:  0.4624639083172795\n",
      "cohen_kappa_score:  0.023323821332342065\n",
      "roc_auc_score:  0.7381099422353801\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344dfe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.4373 - categorical_accuracy: 0.8102\n",
      "Epoch 2/2\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.4169 - categorical_accuracy: 0.8179\n",
      "4259/4259 [==============================] - 11s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.834581\n",
      "Precision: 0.854720\n",
      "Recall: 0.958344\n",
      "F1 score: 0.903571\n",
      "Cohens kappa: 0.335330\n",
      "ROC AUC: 0.810961\n",
      "\\Confusion Matrix\n",
      "[[  8118  17953]\n",
      " [  4591 105622]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.836107\n",
      "Precision: 0.637422\n",
      "Recall: 0.313640\n",
      "F1 score: 0.420416\n",
      "Cohens kappa: 0.337617\n",
      "ROC AUC: 0.811643\n",
      "\\Confusion Matrix\n",
      "[[105847   4608]\n",
      " [ 17728   8101]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8353438408030289\n",
      "precision:  0.7460710524720184\n",
      "recall:  0.6359920021290034\n",
      "f1_score:  0.661993484490602\n",
      "cohen_kappa_score:  0.33647350925450514\n",
      "roc_auc_score:  0.8113022054130092\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54d3350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n",
      "25466/25466 [==============================] - 201s 8ms/step - loss: 0.4338 - categorical_accuracy: 0.8114\n",
      "Epoch 2/2\n",
      "25466/25466 [==============================] - 204s 8ms/step - loss: 0.4159 - categorical_accuracy: 0.8178\n",
      "4259/4259 [==============================] - 11s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.837897\n",
      "Precision: 0.881519\n",
      "Recall: 0.923702\n",
      "F1 score: 0.902118\n",
      "Cohens kappa: 0.432244\n",
      "ROC AUC: 0.808352\n",
      "\\Confusion Matrix\n",
      "[[ 12388  13683]\n",
      " [  8409 101804]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.839174\n",
      "Precision: 0.594028\n",
      "Recall: 0.478300\n",
      "F1 score: 0.529919\n",
      "Cohens kappa: 0.434271\n",
      "ROC AUC: 0.808918\n",
      "\\Confusion Matrix\n",
      "[[102012   8443]\n",
      " [ 13475  12354]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8385357048516333\n",
      "precision:  0.7377735584145093\n",
      "recall:  0.7010009356556297\n",
      "f1_score:  0.7160183924566\n",
      "cohen_kappa_score:  0.4332579370118738\n",
      "roc_auc_score:  0.8086349563079785\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, 16\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb5a67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/5\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.4383 - categorical_accuracy: 0.8100\n",
      "Epoch 2/5\n",
      "12733/12733 [==============================] - 108s 8ms/step - loss: 0.4176 - categorical_accuracy: 0.8177\n",
      "Epoch 3/5\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.4125 - categorical_accuracy: 0.8191\n",
      "Epoch 4/5\n",
      "12733/12733 [==============================] - 95s 7ms/step - loss: 0.4080 - categorical_accuracy: 0.8202\n",
      "Epoch 5/5\n",
      "12733/12733 [==============================] - 96s 8ms/step - loss: 0.4041 - categorical_accuracy: 0.8216\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.833341\n",
      "Precision: 0.874642\n",
      "Recall: 0.926742\n",
      "F1 score: 0.899939\n",
      "Cohens kappa: 0.404078\n",
      "ROC AUC: 0.800767\n",
      "\\Confusion Matrix\n",
      "[[ 11432  14639]\n",
      " [  8074 102139]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.834559\n",
      "Precision: 0.584128\n",
      "Recall: 0.441132\n",
      "F1 score: 0.502658\n",
      "Cohens kappa: 0.405740\n",
      "ROC AUC: 0.801354\n",
      "\\Confusion Matrix\n",
      "[[102343   8112]\n",
      " [ 14435  11394]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8339496932875465\n",
      "precision:  0.7293852223285127\n",
      "recall:  0.6839369576355057\n",
      "f1_score:  0.7012983773035115\n",
      "cohen_kappa_score:  0.40490902268832796\n",
      "roc_auc_score:  0.8010603411401638\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 5, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f68a5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/8\n",
      "12733/12733 [==============================] - 97s 7ms/step - loss: 0.4361 - categorical_accuracy: 0.8112\n",
      "Epoch 2/8\n",
      "12733/12733 [==============================] - 95s 7ms/step - loss: 0.4176 - categorical_accuracy: 0.8172\n",
      "Epoch 3/8\n",
      "12733/12733 [==============================] - 94s 7ms/step - loss: 0.4136 - categorical_accuracy: 0.8185\n",
      "Epoch 4/8\n",
      "12733/12733 [==============================] - 93s 7ms/step - loss: 0.4097 - categorical_accuracy: 0.8201\n",
      "Epoch 5/8\n",
      "12733/12733 [==============================] - 99s 8ms/step - loss: 0.4057 - categorical_accuracy: 0.8211\n",
      "Epoch 6/8\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.4024 - categorical_accuracy: 0.8220\n",
      "Epoch 7/8\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.3994 - categorical_accuracy: 0.8236\n",
      "Epoch 8/8\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.3966 - categorical_accuracy: 0.8257\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.825027\n",
      "Precision: 0.843990\n",
      "Recall: 0.961338\n",
      "F1 score: 0.898850\n",
      "Cohens kappa: 0.270903\n",
      "ROC AUC: 0.790486\n",
      "\\Confusion Matrix\n",
      "[[  6486  19585]\n",
      " [  4261 105952]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.826539\n",
      "Precision: 0.601842\n",
      "Recall: 0.250416\n",
      "F1 score: 0.353675\n",
      "Cohens kappa: 0.272669\n",
      "ROC AUC: 0.791027\n",
      "\\Confusion Matrix\n",
      "[[106176   4279]\n",
      " [ 19361   6468]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8257829238942209\n",
      "precision:  0.7229162963197717\n",
      "recall:  0.6058773489671937\n",
      "f1_score:  0.6262625089414194\n",
      "cohen_kappa_score:  0.2717859663731414\n",
      "roc_auc_score:  0.7907564811606324\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 8, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(64,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22c5897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/2\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.4344 - categorical_accuracy: 0.8118\n",
      "Epoch 2/2\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.4166 - categorical_accuracy: 0.8182\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.837450\n",
      "Precision: 0.867720\n",
      "Recall: 0.942711\n",
      "F1 score: 0.903662\n",
      "Cohens kappa: 0.389498\n",
      "ROC AUC: 0.801845\n",
      "\\Confusion Matrix\n",
      "[[ 10232  15839]\n",
      " [  6314 103899]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.838815\n",
      "Precision: 0.616705\n",
      "Recall: 0.395060\n",
      "F1 score: 0.481605\n",
      "Cohens kappa: 0.391551\n",
      "ROC AUC: 0.802580\n",
      "\\Confusion Matrix\n",
      "[[104113   6342]\n",
      " [ 15625  10204]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8381321358339937\n",
      "precision:  0.7422122323735725\n",
      "recall:  0.6688853744762389\n",
      "f1_score:  0.692633402147532\n",
      "cohen_kappa_score:  0.39052467947206976\n",
      "roc_auc_score:  0.8022125321575377\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 2, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "#model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "model.fit(X_train_data, y_train_data, epochs=epochs, verbose=verbose, batch_size=batch_size) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(X_test_data, y_test_data) # , batch_size=batch_size, verbose=0\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac210e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/10\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.4598 - categorical_accuracy: 0.8022\n",
      "Epoch 2/10\n",
      "12733/12733 [==============================] - 95s 7ms/step - loss: 0.4425 - categorical_accuracy: 0.8091\n",
      "Epoch 3/10\n",
      "12733/12733 [==============================] - 105s 8ms/step - loss: 0.4332 - categorical_accuracy: 0.8134\n",
      "Epoch 4/10\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.4240 - categorical_accuracy: 0.8184\n",
      "Epoch 5/10\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.4192 - categorical_accuracy: 0.8206\n",
      "Epoch 6/10\n",
      "12733/12733 [==============================] - 95s 7ms/step - loss: 0.4171 - categorical_accuracy: 0.8217\n",
      "Epoch 7/10\n",
      "12733/12733 [==============================] - 94s 7ms/step - loss: 0.4128 - categorical_accuracy: 0.8233\n",
      "Epoch 8/10\n",
      "12733/12733 [==============================] - 95s 7ms/step - loss: 0.4088 - categorical_accuracy: 0.8246\n",
      "Epoch 9/10\n",
      "12733/12733 [==============================] - 94s 7ms/step - loss: 0.4075 - categorical_accuracy: 0.8246\n",
      "Epoch 10/10\n",
      "12733/12733 [==============================] - 93s 7ms/step - loss: 0.4070 - categorical_accuracy: 0.8242\n",
      "4259/4259 [==============================] - 10s 2ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.811585\n",
      "Precision: 0.811815\n",
      "Recall: 0.998467\n",
      "F1 score: 0.895519\n",
      "Cohens kappa: 0.031834\n",
      "ROC AUC: 0.803799\n",
      "\\Confusion Matrix\n",
      "[[   562  25509]\n",
      " [   169 110044]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.813346\n",
      "Precision: 0.767442\n",
      "Recall: 0.021720\n",
      "F1 score: 0.042244\n",
      "Cohens kappa: 0.032147\n",
      "ROC AUC: 0.804213\n",
      "\\Confusion Matrix\n",
      "[[110285    170]\n",
      " [ 25268    561]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.812465146312113\n",
      "precision:  0.7896285825899387\n",
      "recall:  0.5100931889608777\n",
      "f1_score:  0.4688812386211431\n",
      "cohen_kappa_score:  0.03199067271969375\n",
      "roc_auc_score:  0.8040056464962966\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 10, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511bf6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=[ 2 9 ]\n",
      "output shape: 2\n",
      "Epoch 1/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.4590 - categorical_accuracy: 0.8030\n",
      "Epoch 2/50\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.4434 - categorical_accuracy: 0.8100\n",
      "Epoch 3/50\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.4293 - categorical_accuracy: 0.8150\n",
      "Epoch 4/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.4219 - categorical_accuracy: 0.8199\n",
      "Epoch 5/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.4170 - categorical_accuracy: 0.8221\n",
      "Epoch 6/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.4119 - categorical_accuracy: 0.8238\n",
      "Epoch 7/50\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.4077 - categorical_accuracy: 0.8251\n",
      "Epoch 8/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.4060 - categorical_accuracy: 0.8257\n",
      "Epoch 9/50\n",
      "12733/12733 [==============================] - 109s 9ms/step - loss: 0.4021 - categorical_accuracy: 0.8273\n",
      "Epoch 10/50\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.3993 - categorical_accuracy: 0.8283\n",
      "Epoch 11/50\n",
      "12733/12733 [==============================] - 108s 9ms/step - loss: 0.3993 - categorical_accuracy: 0.8300\n",
      "Epoch 12/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3971 - categorical_accuracy: 0.8309\n",
      "Epoch 13/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3950 - categorical_accuracy: 0.8312\n",
      "Epoch 14/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3940 - categorical_accuracy: 0.8327\n",
      "Epoch 15/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3929 - categorical_accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.3905 - categorical_accuracy: 0.8341\n",
      "Epoch 17/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3910 - categorical_accuracy: 0.8341\n",
      "Epoch 18/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3879 - categorical_accuracy: 0.8352\n",
      "Epoch 19/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3881 - categorical_accuracy: 0.8350\n",
      "Epoch 20/50\n",
      "12733/12733 [==============================] - 99s 8ms/step - loss: 0.3894 - categorical_accuracy: 0.8346\n",
      "Epoch 21/50\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.3904 - categorical_accuracy: 0.8334\n",
      "Epoch 22/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3897 - categorical_accuracy: 0.8342\n",
      "Epoch 23/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3903 - categorical_accuracy: 0.8338\n",
      "Epoch 24/50\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.3898 - categorical_accuracy: 0.8341\n",
      "Epoch 25/50\n",
      "12733/12733 [==============================] - 106s 8ms/step - loss: 0.3878 - categorical_accuracy: 0.8345\n",
      "Epoch 26/50\n",
      "12733/12733 [==============================] - 105s 8ms/step - loss: 0.3843 - categorical_accuracy: 0.8349\n",
      "Epoch 27/50\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.3828 - categorical_accuracy: 0.8358\n",
      "Epoch 28/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3826 - categorical_accuracy: 0.8355\n",
      "Epoch 29/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3831 - categorical_accuracy: 0.8355\n",
      "Epoch 30/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3836 - categorical_accuracy: 0.8350\n",
      "Epoch 31/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3820 - categorical_accuracy: 0.8361\n",
      "Epoch 32/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3827 - categorical_accuracy: 0.8364\n",
      "Epoch 33/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3822 - categorical_accuracy: 0.8366\n",
      "Epoch 34/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3830 - categorical_accuracy: 0.8356\n",
      "Epoch 35/50\n",
      "12733/12733 [==============================] - 104s 8ms/step - loss: 0.3850 - categorical_accuracy: 0.8356\n",
      "Epoch 36/50\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.3855 - categorical_accuracy: 0.8347\n",
      "Epoch 37/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3863 - categorical_accuracy: 0.8347\n",
      "Epoch 38/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3848 - categorical_accuracy: 0.8353\n",
      "Epoch 39/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3860 - categorical_accuracy: 0.8350\n",
      "Epoch 40/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3854 - categorical_accuracy: 0.8350\n",
      "Epoch 41/50\n",
      "12733/12733 [==============================] - 99s 8ms/step - loss: 0.3842 - categorical_accuracy: 0.8349\n",
      "Epoch 42/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3815 - categorical_accuracy: 0.8371\n",
      "Epoch 43/50\n",
      "12733/12733 [==============================] - 101s 8ms/step - loss: 0.3815 - categorical_accuracy: 0.8366\n",
      "Epoch 44/50\n",
      "12733/12733 [==============================] - 105s 8ms/step - loss: 0.3801 - categorical_accuracy: 0.8379\n",
      "Epoch 45/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3783 - categorical_accuracy: 0.8392\n",
      "Epoch 46/50\n",
      "12733/12733 [==============================] - 102s 8ms/step - loss: 0.3792 - categorical_accuracy: 0.8391\n",
      "Epoch 47/50\n",
      "12733/12733 [==============================] - 103s 8ms/step - loss: 0.3780 - categorical_accuracy: 0.8391\n",
      "Epoch 48/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3794 - categorical_accuracy: 0.8397\n",
      "Epoch 49/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3783 - categorical_accuracy: 0.8402\n",
      "Epoch 50/50\n",
      "12733/12733 [==============================] - 100s 8ms/step - loss: 0.3775 - categorical_accuracy: 0.8405\n",
      "4259/4259 [==============================] - 12s 3ms/step\n",
      "\n",
      "awake\n",
      "Accuracy: 0.814373\n",
      "Precision: 0.814395\n",
      "Recall: 0.997886\n",
      "F1 score: 0.896851\n",
      "Cohens kappa: 0.057310\n",
      "ROC AUC: 0.795988\n",
      "\\Confusion Matrix\n",
      "[[  1006  25065]\n",
      " [   233 109980]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.816119\n",
      "Precision: 0.810331\n",
      "Recall: 0.038871\n",
      "F1 score: 0.074184\n",
      "Cohens kappa: 0.057837\n",
      "ROC AUC: 0.796440\n",
      "\\Confusion Matrix\n",
      "[[110220    235]\n",
      " [ 24825   1004]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8152461037245751\n",
      "precision:  0.8123630568126471\n",
      "recall:  0.5183784741286007\n",
      "f1_score:  0.4855175083038018\n",
      "cohen_kappa_score:  0.057573195982596304\n",
      "roc_auc_score:  0.7962138970540978\n"
     ]
    }
   ],
   "source": [
    "print(\"input_shape=[\", X_train_data.shape[1], X_train_data.shape[2],\"]\")\n",
    "print(\"output shape:\",len(outputClasses))\n",
    "\n",
    "verbose, epochs, batch_size = 1, 50, BATCH_SIZE\n",
    "#verbose, epochs, batch_size = 1, 3, 16\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,activation=\"tanh\", \n",
    "          input_shape=[X_train_data.shape[1], X_train_data.shape[2]]))\n",
    "#model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(len(outputClasses), activation='softmax'))#softmax,sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "          #loss='binary_crossentropy',loss='categorical_crossentropy',\n",
    "          #loss='binary_crossentropy',  sparse_categorical_crossentropy     \n",
    "# fit network\n",
    "model.fit(train_dataset_series1, epochs=epochs, verbose=verbose) #, batch_size=batch_size, validation_split=0.1\n",
    "# evaluate model\n",
    "#accuracy = model.evaluate(test_dataset_series1) # , batch_size=batch_size, verbose=0\n",
    "# predict\n",
    "yhat_probs = model.predict(X_test_data)\n",
    "# predict crisp classes for test set deprecated\n",
    "\n",
    "probss = pd.DataFrame(data=yhat_probs,columns=['awake','asleep'])\n",
    "valuesY = pd.DataFrame(data=y_test_data,columns=['awake','asleep'])\n",
    "\n",
    "#valuesY = y_test_data\n",
    "print('')\n",
    "print('awake')\n",
    "test = list()\n",
    "res = printMetrics(valuesY['awake'],probss['awake'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('asleep')\n",
    "res = printMetrics(valuesY['asleep'],probss['asleep'])\n",
    "test.append(res)\n",
    "print('')\n",
    "print('Global')\n",
    "showGlobalMetrics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a707fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
