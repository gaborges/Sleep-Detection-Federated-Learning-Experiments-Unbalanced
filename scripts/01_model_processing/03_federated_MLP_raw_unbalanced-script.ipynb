{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cc3553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "np.random.seed(0)\n",
    "from collections import Counter\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime;\n",
    "  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "280fd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    results['matrix'] = np.array(matrix,dtype=object)\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    array.append(np.array(matrix,dtype=object))\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "    \n",
    "def create_dataset_time_series_with_one_output(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        v = X.iloc[i:(i + window_time_steps)].values\n",
    "        labels = y.iloc[i: i + window_time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e68b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 3\n",
    "NUM_EPOCHS = EPOCHS\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "#TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "# outputs\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "230d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "# input folder\n",
    "inputFolders = baseFolder\n",
    "\n",
    "            \n",
    "dsTrain = ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "            'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4', \n",
    "            'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "            'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "            'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "            'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "            'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "            'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "\n",
    "\n",
    "# client datasets used on the training process\n",
    "dsTrain =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "            '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "            '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "            '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "            #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "            '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "            'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "            'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "            'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "            'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "            'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "            'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', \n",
    "            'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "            'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "            'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "            'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "            'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "            'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "            'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "            #['PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc'], \n",
    "            'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "            #['rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw'], \n",
    "            #['RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI'], \n",
    "            'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "            #['VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is'], \n",
    "            #['Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw'], \n",
    "            #['XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA'], \n",
    "            #['YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw'], \n",
    "            #['ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM'], \n",
    "            #['ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d44b239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_numeric.csv\n",
      "1   ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_numeric.csv\n",
      "2   ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_numeric.csv\n",
      "3   ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_numeric.csv\n",
      "4   ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_numeric.csv\n",
      "5   ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_numeric.csv\n",
      "6   ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_numeric.csv\n",
      "7   ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_numeric.csv\n",
      "8   ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_numeric.csv\n",
      "9   ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_numeric.csv\n",
      "10   ../data_2019_processed/student_DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA_numeric.csv\n",
      "11   ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_numeric.csv\n",
      "12   ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_numeric.csv\n",
      "13   ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_numeric.csv\n",
      "14   ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_numeric.csv\n",
      "15   ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_numeric.csv\n",
      "16   ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_numeric.csv\n",
      "17   ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_numeric.csv\n",
      "18   ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_numeric.csv\n",
      "19   ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_numeric.csv\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "# load cliend data\n",
    "clientList = []\n",
    "\n",
    "for i in range(0,len(dsTrain)):\n",
    "    print (i,\" \", str(inputFolders)+\"student_\"+dsTrain[i]+\"_numeric.csv\") #_numeric\n",
    "    # load client data\n",
    "    dataset = pd.read_csv(inputFolders+\"student_\"+dsTrain[i]+\"_numeric.csv\")\n",
    "    \n",
    "    # print(dataset)\n",
    "    y_train = dataset['class'].copy()\n",
    "    \n",
    "    # does not add datasets that dont have instances from both classes\n",
    "    if y_train.sum() != 0 and (y_train.sum() != len(y_train)):\n",
    "        clientList.append(dataset)\n",
    "        \n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c7fdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 12.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>light</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>proximity</th>\n",
       "      <th>sound</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655565</td>\n",
       "      <td>0.906151</td>\n",
       "      <td>0.115358</td>\n",
       "      <td>2018-05-15 02:46:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:27</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.906052</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>2018-05-15 02:47:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:28</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>2018-05-15 02:48:57</td>\n",
       "      <td>asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136281</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136282</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136283</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136284</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136285</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136286 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        activity  location  timestamp  day_of_week     light  phone_lock  \\\n",
       "0           0.00       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "1           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "2           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "3           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "4           0.25       1.0   0.000647     1.000000  0.000000         0.0   \n",
       "...          ...       ...        ...          ...       ...         ...   \n",
       "136281      0.25       1.0   0.007015     0.166667  0.000056         1.0   \n",
       "136282      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136283      0.25       1.0   0.007015     0.166667  0.000078         1.0   \n",
       "136284      0.25       1.0   0.007016     0.166667  0.000085         1.0   \n",
       "136285      0.50       1.0   0.007016     0.166667  0.000000         1.0   \n",
       "\n",
       "        proximity     sound  time_to_next_alarm  minutes_day  \\\n",
       "0             1.0  0.655565            0.906151     0.115358   \n",
       "1             1.0  0.567296            0.906052     0.116053   \n",
       "2             1.0  0.567296            0.906052     0.116053   \n",
       "3             1.0  0.660604            0.905952     0.116748   \n",
       "4             1.0  0.660604            0.905952     0.116748   \n",
       "...           ...       ...                 ...          ...   \n",
       "136281        1.0  0.000000            0.000099     0.510076   \n",
       "136282        1.0  0.000000            0.000694     0.512856   \n",
       "136283        1.0  0.000000            0.000595     0.513551   \n",
       "136284        1.0  0.000000            0.000595     0.513551   \n",
       "136285        0.0  0.000000            0.000496     0.514246   \n",
       "\n",
       "             timestamp_text   class  \n",
       "0       2018-05-15 02:46:57  asleep  \n",
       "1       2018-05-15 02:47:27  asleep  \n",
       "2       2018-05-15 02:47:57  asleep  \n",
       "3       2018-05-15 02:48:28  asleep  \n",
       "4       2018-05-15 02:48:57  asleep  \n",
       "...                     ...     ...  \n",
       "136281  2018-06-13 12:14:37   awake  \n",
       "136282  2018-06-13 12:18:08   awake  \n",
       "136283  2018-06-13 12:19:08   awake  \n",
       "136284  2018-06-13 12:19:38   awake  \n",
       "136285  2018-06-13 12:20:08   awake  \n",
       "\n",
       "[136286 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7473fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_numerical_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd6842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float64\n",
      " 1   location            136286 non-null  float64\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float64\n",
      " 4   light               136286 non-null  float64\n",
      " 5   phone_lock          136286 non-null  float64\n",
      " 6   proximity           136286 non-null  float64\n",
      " 7   sound               136286 non-null  float64\n",
      " 8   time_to_next_alarm  136286 non-null  float64\n",
      " 9   minutes_day         136286 non-null  float64\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  uint8  \n",
      " 13  asleep              136286 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0830f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136286 entries, 0 to 136285\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            136286 non-null  float32\n",
      " 1   location            136286 non-null  float32\n",
      " 2   timestamp           136286 non-null  float64\n",
      " 3   day_of_week         136286 non-null  float32\n",
      " 4   light               136286 non-null  float32\n",
      " 5   phone_lock          136286 non-null  float32\n",
      " 6   proximity           136286 non-null  float32\n",
      " 7   sound               136286 non-null  float32\n",
      " 8   time_to_next_alarm  136286 non-null  float32\n",
      " 9   minutes_day         136286 non-null  float32\n",
      " 10  timestamp_text      136286 non-null  object \n",
      " 11  class               136286 non-null  object \n",
      " 12  awake               136286 non-null  float32\n",
      " 13  asleep              136286 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56557625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "021a0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa9c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(12, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9357a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12)                120       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 12)                156       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302\n",
      "Trainable params: 302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17708ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    #keras_model = create_keras_model()\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=client_train_dataset.element_spec,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), #BinaryCrossentropy\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58fa47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avg_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),#client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9279e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,12],\n",
      "      float32[12],\n",
      "      float32[12,12],\n",
      "      float32[12],\n",
      "      float32[12,2],\n",
      "      float32[2]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(fed_avg_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c2f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fed_avg_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da066c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Start timestamp: 1678185243.223585 2023-03-07 10:34:03.223585\n",
      "round  0, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.87853754), ('loss', 0.3070766), ('num_examples', 1222353), ('num_batches', 38210)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "0.9974452 0.0025547408 0.5\n",
      "[[0.8547516  0.14524846]\n",
      " [0.86070037 0.13929966]\n",
      " [0.86070037 0.13929966]\n",
      " ...\n",
      " [0.8969394  0.10306061]\n",
      " [0.8969394  0.10306061]\n",
      " [0.93334544 0.06665461]]\n",
      "\n",
      "awake\n",
      "Accuracy: 0.704276\n",
      "Precision: 0.705246\n",
      "Recall: 0.994504\n",
      "F1 score: 0.825263\n",
      "Cohens kappa: 0.020042\n",
      "ROC AUC: 0.507230\n",
      "\\Confusion Matrix\n",
      "[[  810 39777]\n",
      " [  526 95173]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.704276\n",
      "Precision: 0.606287\n",
      "Recall: 0.019957\n",
      "F1 score: 0.038642\n",
      "Cohens kappa: 0.020042\n",
      "ROC AUC: 0.507230\n",
      "\\Confusion Matrix\n",
      "[[95173   526]\n",
      " [39777   810]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.7042763013075445\n",
      "precision:  0.6557669063503226\n",
      "recall:  0.5072303644793231\n",
      "f1_score:  0.4319524506171141\n",
      "cohen_kappa_score:  0.02004165260027857\n",
      "roc_auc_score:  0.5072303644793232\n",
      "\n",
      "0 End timestamp: 1678185450.975947 2023-03-07 10:37:30.975947\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roundData = []\n",
    "\n",
    "columns = ['NN_type','units','epochs','batch_size','max_iterations','Users',\n",
    "           'round_iteration','start_time','end_time','round_time_s','round_time_m',\n",
    "           'class','accuracy','precision','recall','f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "           'TP','FP','FN','TN']\n",
    "\n",
    "MAX_ITERATIONS = 120\n",
    "#NUM_EPOCHS\n",
    "#BATCH_SIZE\n",
    "NN_type = 'MLP'\n",
    "UNITS_NUMBER = 12\n",
    "USER_NUMBER = len(dsTrain)\n",
    "\n",
    "generalData = [NN_type,UNITS_NUMBER,NUM_EPOCHS,BATCH_SIZE,MAX_ITERATIONS,USER_NUMBER]\n",
    "\n",
    "for i in range(0,MAX_ITERATIONS):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}, metrics={}'.format(i,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data,verbose=0)\n",
    "\n",
    "    maxX = yhat_probs.max()\n",
    "    minX = yhat_probs.min()\n",
    "    avgX = yhat_probs.mean()\n",
    "\n",
    "    print(maxX,minX,avgX)\n",
    "    print(yhat_probs)\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #printMetrics(y_test,yhat_probs)\n",
    "    test = list()\n",
    "\n",
    "    xx = yhat_probs.round()\n",
    "\n",
    "    y_test2 = pd.DataFrame(data=xx,columns=['awake','asleep']) \n",
    "    y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "    \n",
    "    # generate time metrics\n",
    "    current_time2 = datetime.datetime.now()\n",
    "    time_stamp2 = current_time2.timestamp()\n",
    "    processing_time_s = (time_stamp2-time_stamp)\n",
    "    # generate general metrics\n",
    "    rowData = [i,current_time,current_time2,processing_time_s,(processing_time_s)/60]\n",
    "\n",
    "    print('')\n",
    "    print('awake')    \n",
    "    res,resA = printMetrics(y_test_label_label['awake'],y_test2['awake'])\n",
    "    test.append(res)\n",
    "   \n",
    "    #columns = ['NN_type','units','epochs','batch_size','max_iterations',''Users',\n",
    "    #            round_iteration','start_time','end_time','round_time_s','round_time_m',\n",
    "    #           'class','accuracy','precision','recall','f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "    #           'TP','FP','FN','TN']\n",
    "    # new data\n",
    "    classData = []\n",
    "    classData = np.concatenate((np.array(['awake'],dtype=object), resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res,resA = printMetrics(y_test_label_label['asleep'],y_test2['asleep'])\n",
    "    test.append(res)\n",
    "    # new data\n",
    "    classData = np.concatenate((np.array(['asleep'],dtype=object), resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    resA = showGlobalMetrics(test) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    # new data\n",
    "    classData = np.concatenate((np.array(['avg'],dtype=object), resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    print('')\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time2)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95aaa901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_type</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_iterations</th>\n",
       "      <th>Users</th>\n",
       "      <th>round_iteration</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>round_time_s</th>\n",
       "      <th>...</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-07 10:34:03.223585</td>\n",
       "      <td>2023-03-07 10:37:30.975947</td>\n",
       "      <td>207.752362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705246</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>0.825263</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.50723</td>\n",
       "      <td>[[810, 39777], [526, 95173]]</td>\n",
       "      <td>810.0</td>\n",
       "      <td>39777.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>95173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-07 10:34:03.223585</td>\n",
       "      <td>2023-03-07 10:37:30.975947</td>\n",
       "      <td>207.752362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606287</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>0.038642</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.50723</td>\n",
       "      <td>[[95173, 526], [39777, 810]]</td>\n",
       "      <td>95173.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>39777.0</td>\n",
       "      <td>810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-07 10:34:03.223585</td>\n",
       "      <td>2023-03-07 10:37:30.975947</td>\n",
       "      <td>207.752362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655767</td>\n",
       "      <td>0.507230</td>\n",
       "      <td>0.431952</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.50723</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  NN_type units epochs batch_size max_iterations Users  round_iteration  \\\n",
       "0      NN    12      3         32              1    20                0   \n",
       "1      NN    12      3         32              1    20                0   \n",
       "2      NN    12      3         32              1    20                0   \n",
       "\n",
       "                  start_time                   end_time  round_time_s  ...  \\\n",
       "0 2023-03-07 10:34:03.223585 2023-03-07 10:37:30.975947    207.752362  ...   \n",
       "1 2023-03-07 10:34:03.223585 2023-03-07 10:37:30.975947    207.752362  ...   \n",
       "2 2023-03-07 10:34:03.223585 2023-03-07 10:37:30.975947    207.752362  ...   \n",
       "\n",
       "   precision    recall  f1_score  cohen_kappa_score  roc_auc_score  \\\n",
       "0   0.705246  0.994504  0.825263           0.020042        0.50723   \n",
       "1   0.606287  0.019957  0.038642           0.020042        0.50723   \n",
       "2   0.655767  0.507230  0.431952           0.020042        0.50723   \n",
       "\n",
       "               confusion_matrix       TP       FP       FN       TN  \n",
       "0  [[810, 39777], [526, 95173]]    810.0  39777.0    526.0  95173.0  \n",
       "1  [[95173, 526], [39777, 810]]  95173.0    526.0  39777.0    810.0  \n",
       "2                          None      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMetrics = pd.DataFrame(data=roundData,columns=columns) \n",
    "\n",
    "dataMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d310c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMetrics.to_csv(\"result3epochsMLPunbalanced.csv\", sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2ee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
